# -*- coding: utf-8 -*-
"""app72.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XFqBVm419t1dYgWBo-kKiPHwfzat3T1C
"""

# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.impute import SimpleImputer

# --- Page Configuration ---
st.set_page_config(
    page_title="India Air Quality Analysis",
    page_icon="üå§Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Custom CSS for Polishing ---
# FIXED: Combined all styles into one valid Python string
st.markdown("""
    <style>
    /* 1. Main Background: Light Red */
    .stApp {
        background-color: #FFCCCB;
    }

    /* 2. Sidebar Background: Light Sea Blue */
    [data-testid="stSidebar"] {
        background-color: #ADD8E6;
    }

    /* 3. Button Styling */
    .stButton>button {
        width: 100%;
        border-radius: 10px;
        height: 3em;
        background-color: #4CAF50; /* kept the green button from your snippet */
        color: white;
    }

    /* 4. Heading Colors */
    h1 {
        color: #2E4053;
    }
    h2 {
        color: #34495E;
    }
    </style>
""", unsafe_allow_html=True)

# --- Data Loading & Caching ---
@st.cache_data
def load_data():
    # Attempt to load data; if not found, ask user to upload
    try:
        df = pd.read_csv("all_data_combined 18.csv")
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        return df
    except FileNotFoundError:
        return None

# --- Preprocessing Function ---
def preprocess_data(df):
    # Select numeric columns for imputation
    numeric_cols = df.select_dtypes(include=[np.number]).columns

    # Imputation Strategy: Fill with median to handle skewness
    imputer = SimpleImputer(strategy='median')
    df[numeric_cols] = imputer.fit_transform(df[numeric_cols])

    # Drop rows where target AQI might still be missing or problematic
    df = df.dropna(subset=['AQI'])
    return df

# --- Main Application Logic ---
def main():
    # Sidebar Navigation
    st.sidebar.title("Navigation")
    page = st.sidebar.radio("Go to", [" Home & Data Overview", " Exploratory Data Analysis", " Modelling & Prediction"])

    # Load Data
    data = load_data()

    if data is None:
        st.error("Welcome to the AQI Machine Learning Prediction")
        uploaded_file = st.sidebar.file_uploader("Upload CSV", type=["csv"])
        if uploaded_file is not None:
            data = pd.read_csv(uploaded_file)
            data['Date'] = pd.to_datetime(data['Date'], errors='coerce')
        else:
            st.stop()

    # --- PAGE 1: HOME & DATA OVERVIEW ---
    if page == " Home & Data Overview":
        st.title("üå§Ô∏è India Air Quality Analysis Project")
        st.markdown("### CMP7005 - Machine Learning Final Project")
        st.write("This interactive application monitors and forecasts air pollution using a real-world dataset from Indian cities (2015-2020).")

        col1, col2, col3 = st.columns(3)
        col1.metric("Total Records", data.shape[0])
        col2.metric("Total Cities", data['City'].nunique())
        col3.metric("Features", data.shape[1])

        st.divider()

        st.subheader(" Dataset Preview")
        with st.expander("View Raw Data"):
            st.dataframe(data.head(100), use_container_width=True)

        st.subheader(" Statistical Summary")
        with st.expander("View Descriptive Statistics"):
            st.dataframe(data.describe(), use_container_width=True)

        st.subheader(" Missing Values Analysis")
        missing_val = data.isnull().sum()
        fig_missing = px.bar(missing_val, x=missing_val.index, y=missing_val.values,
                             title="Missing Values Count per Feature",
                             labels={'y':'Count', 'x':'Feature'}, color=missing_val.values, color_continuous_scale='Reds')
        st.plotly_chart(fig_missing, use_container_width=True)

    # --- PAGE 2: EXPLORATORY DATA ANALYSIS (EDA) ---
    elif page == " Exploratory Data Analysis":
        st.title(" Exploratory Data Analysis")

        # Sidebar filters for EDA
        st.sidebar.subheader("Filter Settings")
        selected_city = st.sidebar.selectbox("Select City for Analysis", data['City'].unique())

        city_data = data[data['City'] == selected_city]

        # 1. Time Series Analysis
        st.subheader(f"üìà Air Quality Trends in {selected_city}")
        pollutant = st.selectbox("Select Pollutant to visualize", ['PM2.5', 'PM10', 'NO2', 'CO', 'SO2', 'O3', 'AQI'])

        fig_line = px.line(city_data, x='Date', y=pollutant, title=f'{pollutant} Levels Over Time in {selected_city}',
                           markers=True)
        fig_line.update_xaxes(rangeslider_visible=True)
        st.plotly_chart(fig_line, use_container_width=True)

        # 2. Correlation Analysis
        st.subheader(" Correlation Heatmap")
        st.write("Understand the relationship between different pollutants.")

        # Select only numeric columns for correlation
        numeric_df = data.select_dtypes(include=[np.number])
        corr = numeric_df.corr()

        fig_corr = px.imshow(corr, text_auto=True, aspect="auto", color_continuous_scale='Viridis',
                             title="Feature Correlation Matrix")
        st.plotly_chart(fig_corr, use_container_width=True)

        # 3. Distribution Analysis
        st.subheader("Distribution of Pollutants") # Fixed title typo "bar_chart"
        col1, col2 = st.columns(2)

        with col1:
            dist_pollutant = st.selectbox("Select Pollutant for Histogram", numeric_df.columns, index=2)
            fig_hist = px.histogram(data, x=dist_pollutant, nbins=50, title=f"Distribution of {dist_pollutant}",
                                    color_discrete_sequence=['#3366CC'])
            st.plotly_chart(fig_hist, use_container_width=True)

        with col2:
            fig_box = px.box(data, x='AQI_Bucket', y='PM2.5', title="PM2.5 Levels by AQI Category",
                             color='AQI_Bucket')
            st.plotly_chart(fig_box, use_container_width=True)

    # --- PAGE 3: MODELLING & PREDICTION ---
    elif page == " Modelling & Prediction":
        st.title(" AQI Prediction Model")
        st.write("This section uses a Random Forest Regressor to predict the Air Quality Index (AQI) based on pollutant levels.")

        # Data Preparation
        df_model = preprocess_data(data.copy())

        # Features selection
        features = ['PM2.5', 'PM10', 'NO', 'NO2', 'CO', 'SO2', 'O3']
        target = 'AQI'

        X = df_model[features]
        y = df_model[target]

        # Train/Test Split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Model Training (Cached)
        @st.cache_resource
        def train_model(X_train, y_train):
            model = RandomForestRegressor(n_estimators=50, random_state=42)
            model.fit(X_train, y_train)
            return model

        with st.spinner("Training Model... Please wait..."):
            rf_model = train_model(X_train, y_train)

        # Model Performance
        y_pred = rf_model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))

        st.success("Model Trained Successfully!")

        col1, col2 = st.columns(2)
        col1.metric("Model R¬≤ Score", f"{r2:.2f}")
        col2.metric("RMSE", f"{rmse:.2f}")

        st.divider()

        # User Prediction Interface
        st.subheader(" Make a Prediction")
        st.write("Adjust the sliders below to simulate pollutant levels:")

        input_cols = st.columns(3)
        user_inputs = {}

        for i, feature in enumerate(features):
            with input_cols[i % 3]:
                min_val = float(df_model[feature].min())
                max_val = float(df_model[feature].max())
                mean_val = float(df_model[feature].mean())
                user_inputs[feature] = st.slider(f"{feature}", min_val, max_val, mean_val)

        # Predict Button
        if st.button("Predict AQI"):
            input_df = pd.DataFrame([user_inputs])
            prediction = rf_model.predict(input_df)[0]

            st.markdown(f"### Predicted AQI: <span style='color:green'>{prediction:.2f}</span>", unsafe_allow_html=True)

            # AQI Categorization
            if prediction <= 50: status = "Good (Minimal Impact)"
            elif prediction <= 100: status = "Satisfactory (Minor breathing discomfort to sensitive people)"
            elif prediction <= 200: status = "Moderate (Breathing discomfort to people with lung disease)"
            elif prediction <= 300: status = "Poor (Breathing discomfort to most people on prolonged exposure)"
            elif prediction <= 400: status = "Very Poor (Respiratory illness on prolonged exposure)"
            else: status = "Severe (Affects healthy people and seriously impacts those with existing diseases)"

            st.info(f"Air Quality Status: **{status}**")

if __name__ == "__main__":
    main()
