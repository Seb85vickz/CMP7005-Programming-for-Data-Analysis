# -*- coding: utf-8 -*-
"""Untitled22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IJD21pj9-Qexl388vreFQsduabCECOFc
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from xgboost import XGBRegressor

st.set_page_config(page_title="AQI ML Application", layout="wide")

@st.cache_data
def load_data():
    df = pd.read_csv('all_cities_combined.csv')
    return df

# Sidebar Navigation
st.sidebar.title("Navigation")
page = st.sidebar.radio("Go to", ["Data Overview", "Exploratory Data Analysis", "Modelling & Prediction"])

df = load_data()

# -------------------- DATA OVERVIEW --------------------
if page == "Data Overview":
    st.title("ðŸ“Š Data Overview")
    st.write("This dataset contains air quality measurements collected across multiple cities.")

    st.subheader("Dataset Preview")
    st.dataframe(df.head())

    st.subheader("Shape of Dataset")
    st.write(f"Rows: {df.shape[0]}, Columns: {df.shape[1]}")

    st.subheader("Column Information")
    st.dataframe(pd.DataFrame({
        'Column': df.columns,
        'Non-Null Count': df.notnull().sum(),
        'Data Type': df.dtypes
    }))

    st.subheader("Missing Values")
    st.dataframe(df.isnull().sum())

# -------------------- EDA --------------------
elif page == "Exploratory Data Analysis":
    st.title("ðŸ“ˆ Exploratory Data Analysis (EDA)")

    numeric_df = df.select_dtypes(include=['float64', 'int64'])

    st.subheader("Statistical Summary")
    st.dataframe(numeric_df.describe())

    st.subheader("Correlation Heatmap")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.heatmap(numeric_df.corr(), cmap='coolwarm', ax=ax)
    st.pyplot(fig)

    st.subheader("Feature Distribution")
    feature = st.selectbox("Select Feature", numeric_df.columns)
    fig2, ax2 = plt.subplots()
    sns.histplot(numeric_df[feature], kde=True, ax=ax2)
    st.pyplot(fig2)

# -------------------- MODELLING --------------------
elif page == "Modelling & Prediction":
    st.title("ðŸ¤– Modelling & Prediction")

    df_model = df.dropna()
    df_model = df_model.select_dtypes(include=['float64', 'int64'])

    y = df_model['PM2.5']
    X = df_model.drop(columns=['PM2.5', 'AQI_Bucket'], errors='ignore')

    test_size = st.slider("Test Size", 0.1, 0.4, 0.2)
    n_estimators = st.slider("Number of Trees", 50, 300, 100)
    max_depth = st.slider("Max Depth", 2, 10, 5)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

    model = XGBRegressor(
        n_estimators=n_estimators,
        max_depth=max_depth,
        learning_rate=0.1,
        objective='reg:squarederror',
        random_state=42
    )

    if st.button("Train Model"):
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        st.subheader("Model Performance")
        st.write(f"R2 Score: {r2_score(y_test, y_pred):.3f}")
        st.write(f"RMSE: {mean_squared_error(y_test, y_pred, squared=False):.3f}")
        st.write(f"MAE: {mean_absolute_error(y_test, y_pred):.3f}")

        st.subheader("Actual vs Predicted")
        fig3, ax3 = plt.subplots()
        ax3.scatter(y_test, y_pred, alpha=0.6)
        ax3.set_xlabel("Actual PM2.5")
        ax3.set_ylabel("Predicted PM2.5")
        st.pyplot(fig3)

        st.subheader("Feature Importance")
        importance = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)
        st.bar_chart(importance)