# -*- coding: utf-8 -*-
"""app239876345.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KQe-xa3-y4ZM7f1mM8lbpakFkeEyFG-a
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from xgboost import XGBRegressor

# ==========================================
# 1. APP CONFIGURATION & STYLING
# ==========================================
st.set_page_config(
    page_title="EcoVis: Air Quality AI",
    page_icon="üåç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for a modern, sleek look
st.markdown("""
<style>
    /* Main Background */
    .stApp {
        background: linear-gradient(to right, #f8f9fa, #e9ecef);
    }
    /* Card Style */
    .css-1r6slb0 {
        background-color: white;
        border-radius: 15px;
        padding: 20px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    /* Headlines */
    h1, h2, h3 {
        color: #2c3e50;
        font-family: 'Helvetica', sans-serif;
    }
    /* Sidebar */
    .css-1d391kg {
        background-color: #2c3e50;
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. DATA LOADING FUNCTION
# ==========================================
@st.cache_data
def load_data(url_or_file):
    try:
        df = pd.read_csv(url_or_file)

        # Ensure Date parsing
        if 'Date' in df.columns:
            df['Date'] = pd.to_datetime(df['Date'])
            df['Year'] = df['Date'].dt.year

        return df
    except Exception as e:
        return None

# ==========================================
# 3. SIDEBAR NAVIGATION
# ==========================================
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3222/3222791.png", width=100)
    st.title("Navigation")
    page = st.radio("Go to:", ["üè† Home", "üìä Data Explorer", "üß† Model Trainer", "üîÆ Future Predictor"])

    st.markdown("---")
    st.subheader("Data Source")

    # Option to upload file OR use URL
    data_source = st.radio("Choose source:", ["Upload CSV", "Use GitHub URL"])

    if data_source == "Upload CSV":
        uploaded_file = st.file_uploader("Upload 'final_aqi_cleaned_data.csv'", type=["csv"])
        if uploaded_file:
            df = load_data(uploaded_file)
        else:
            df = None
    else:
        # Default placeholder URL (You can replace this with your actual URL to make it automatic)
        default_url = "https://raw.githubusercontent.com/Seb85vickz/CMP7005-Programming-for-Data-Analysis/refs/heads/main/final_aqi_cleaned_data.csv"
        url = st.text_input("Paste GitHub Raw URL:", value="")
        if url:
            df = load_data(url)
        else:
            df = None

    if df is not None:
        st.success("‚úÖ Data Loaded Successfully")
    else:
        st.warning("‚ö†Ô∏è Please upload data to proceed")

# ==========================================
# 4. PAGE: HOME
# ==========================================
if page == "üè† Home":
    st.title("üåç EcoVis: Air Quality Analytics & Prediction")
    st.markdown("### *Breathing Life into Data*")

    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("""
        Welcome to the **EcoVis Dashboard**. This advanced machine learning application helps you analyze, visualize, and predict Air Quality Index (AQI) trends across major cities.

        **Key Capabilities:**
        - **Deep Dive EDA:** Explore pollutant correlations and seasonal trends.
        - **XGBoost AI:** Train a high-performance Gradient Boosting model.
        - **What-If Analysis:** Simulate pollution scenarios and get instant AQI predictions.
        """)

    with col2:
        st.metric(label="Cities Covered", value=df['City'].nunique() if df is not None else "0")
        st.metric(label="Total Records", value=df.shape[0] if df is not None else "0")

    if df is not None:
        st.subheader("üìå Dataset Snapshot")
        st.dataframe(df.head(10), use_container_width=True)

# ==========================================
# 5. PAGE: DATA EXPLORER (EDA)
# ==========================================
elif page == "üìä Data Explorer":
    if df is None:
        st.error("Please upload data in the sidebar first!")
    else:
        st.title("üìä Interactive Data Exploration")

        # City Filter
        cities = ["All"] + list(df['City'].unique())
        selected_city = st.selectbox("Filter by City:", cities)

        eda_df = df if selected_city == "All" else df[df['City'] == selected_city]

        # Tabs for different plots
        tab1, tab2, tab3 = st.tabs(["üìà Trends", "üå°Ô∏è Correlations", "üì¶ Distributions"])

        with tab1:
            st.subheader("Pollutant Trends Over Time")
            pollutant = st.selectbox("Select Pollutant:", ['PM2.5', 'PM10', 'NO2', 'CO', 'SO2', 'O3'])

            fig_line = px.line(eda_df, x='Date', y=pollutant, color='City' if selected_city == "All" else None,
                               title=f"{pollutant} Levels Over Time", template="plotly_white")
            st.plotly_chart(fig_line, use_container_width=True)

        with tab2:
            st.subheader("Pollutant Correlation Matrix")
            # Filter only numeric columns
            numeric_df = eda_df.select_dtypes(include=[np.number])
            corr = numeric_df.corr()

            fig_corr = px.imshow(corr, text_auto=True, color_continuous_scale='RdBu_r', aspect="auto")
            st.plotly_chart(fig_corr, use_container_width=True)

        with tab3:
            st.subheader("Distribution Analysis")
            dist_col = st.selectbox("Select Column:", ['PM2.5', 'PM10', 'AQI', 'NO2'])
            fig_hist = px.histogram(eda_df, x=dist_col, nbins=50, title=f"Distribution of {dist_col}",
                                    color_discrete_sequence=['#2ecc71'])
            st.plotly_chart(fig_hist, use_container_width=True)

# ==========================================
# 6. PAGE: MODEL TRAINER
# ==========================================
elif page == "üß† Model Trainer":
    if df is None:
        st.error("Please upload data first!")
    else:
        st.title("üß† Train Your AI Model")
        st.markdown("Configure and train an **XGBoost Regressor** to predict PM2.5 levels.")

        # Feature Selection
        target = 'PM2.5'
        # Default features (Removed AQI to prevent data leakage)
        default_features = ['PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene']
        # Filter to only columns present in df
        available_features = [f for f in default_features if f in df.columns]

        selected_features = st.multiselect("Select Input Features:", available_features, default=available_features)

        # Hyperparameters
        col1, col2 = st.columns(2)
        with col1:
            n_estimators = st.slider("Number of Trees (n_estimators)", 50, 500, 100)
        with col2:
            max_depth = st.slider("Max Depth", 3, 15, 6)

        if st.button("üöÄ Train Model Now"):
            with st.spinner("Training model... This usually takes a few seconds..."):
                # Prepare Data
                model_df = df.dropna(subset=[target] + selected_features)
                X = model_df[selected_features]
                y = model_df[target]

                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                # Scaling
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)

                # Training
                model = XGBRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=0.1)
                model.fit(X_train_scaled, y_train)

                # Predictions
                y_pred = model.predict(X_test_scaled)

                # Metrics
                r2 = r2_score(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))

                # Store in session state
                st.session_state['model'] = model
                st.session_state['scaler'] = scaler
                st.session_state['features'] = selected_features

                # Display Metrics
                st.balloons()
                m1, m2 = st.columns(2)
                m1.metric("R¬≤ Score (Accuracy)", f"{r2:.4f}", delta="High is Good")
                m2.metric("RMSE (Error)", f"{rmse:.4f}", delta="-Lower is Better", delta_color="inverse")

                # Feature Importance Plot
                st.subheader("Feature Importance")
                importance_df = pd.DataFrame({
                    'Feature': selected_features,
                    'Importance': model.feature_importances_
                }).sort_values(by='Importance', ascending=True)

                fig_imp = px.bar(importance_df, x='Importance', y='Feature', orientation='h',
                                 title="What drives pollution the most?", color='Importance')
                st.plotly_chart(fig_imp, use_container_width=True)

# ==========================================
# 7. PAGE: FUTURE PREDICTOR
# ==========================================
elif page == "üîÆ Future Predictor":
    st.title("üîÆ Real-Time Prediction Simulator")

    if 'model' not in st.session_state:
        st.warning("‚ö†Ô∏è You must train the model in the 'Model Trainer' tab first!")
    else:
        st.markdown("Adjust the sliders below to simulate atmospheric conditions and predict PM2.5 levels.")

        features = st.session_state['features']
        inputs = {}

        # Create 3 columns for sliders
        cols = st.columns(3)
        for i, feat in enumerate(features):
            col = cols[i % 3]
            min_val = float(df[feat].min())
            max_val = float(df[feat].max())
            mean_val = float(df[feat].mean())
            inputs[feat] = col.slider(f"{feat}", min_val, max_val, mean_val)

        if st.button("üîç Predict Air Quality"):
            # Prepare input
            input_array = np.array([list(inputs.values())])
            input_scaled = st.session_state['scaler'].transform(input_array)

            # Predict
            pred = st.session_state['model'].predict(input_scaled)[0]

            # Display Result
            st.markdown("---")
            res_col1, res_col2 = st.columns([1, 2])

            with res_col1:
                st.metric(label="Predicted PM2.5", value=f"{pred:.2f} ¬µg/m¬≥")

            with res_col2:
                # Interpret Result
                if pred <= 30:
                    status = "Good üü¢"
                    info = "Air quality is satisfactory."
                elif pred <= 60:
                    status = "Satisfactory üü°"
                    info = "Air quality is acceptable."
                elif pred <= 90:
                    status = "Moderate üü†"
                    info = "Breathing discomfort to sensitive people."
                elif pred <= 120:
                    status = "Poor üî¥"
                    info = "Breathing discomfort to most people."
                else:
                    status = "Severe ‚ö´"
                    info = "Emergency conditions. Serious health effects."

                st.subheader(f"Status: {status}")
                st.write(info)