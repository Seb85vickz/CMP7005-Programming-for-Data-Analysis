# -*- coding: utf-8 -*-
"""app129.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1whG6BUCRuaJ-cXfMIzpUqlJZJyjeVJgx
"""

!pip install streamlit
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import os # Added for path handling

# --- Configuration and Initial Setup (From User Snippet 1) ---
st.set_page_config(
    page_title="Air Quality Forecasting System",
    layout="wide"
)

st.title("ðŸŒ Air Quality Forecasting & Analysis Platform")
st.markdown("""
This interactive system allows users to explore air quality data,
perform exploratory analysis, and predict **PM2.5 concentrations**
using an advanced machine learning model.
""")

# --- Multipage Navigation ---
PAGES = {
    "ðŸ  Data Overview": "data_overview",
    "ðŸ“Š Exploratory Data Analysis (EDA)": "eda",
    "ðŸ¤– Modelling & Prediction": "prediction"
}

st.sidebar.title("Navigation")
selection = st.sidebar.radio("Go to", list(PAGES.keys()))
st.sidebar.success("Use the navigation menu above to explore the app.")


# --- Data Handling Functions ---
def clean_data(df):
    """Performs necessary data cleaning steps."""
    # Note: We only drop NA values for the model training/EDA views,
    # but the initial overview should show the raw missing counts.
    return df.drop_duplicates()

@st.cache_data
def load_data(path="data/all_cities_combined.csv"):
    """Loads and performs initial cleaning on the dataset."""
    try:
        df = pd.read_csv(path)
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        # Apply cleaning but keep NAs for overview
        return clean_data(df)
    except FileNotFoundError:
        st.error(f"Error: The file '{path}' was not found. Please check your data directory.")
        return pd.DataFrame() # Return empty frame on failure

# Load Data
df = load_data()


# ==============================================================================
# 1. DATA OVERVIEW PAGE (Based on User Snippet 2)
# ==============================================================================
if selection == "ðŸ  Data Overview":
    st.header("ðŸ“Š Data Overview")

    if not df.empty:
        # --- Shape and Metrics ---
        col1, col2, col3 = st.columns(3)
        col1.metric("Total Records", df.shape[0])
        col2.metric("Features", df.shape[1])
        col3.metric("Total Cities", df['City'].nunique())

        st.subheader("Dataset Preview (First 20 Records)")
        st.dataframe(df.head(20), use_container_width=True)

        # --- Missing Values ---
        st.subheader("Missing Values (%)")

        # Calculate missing values on the raw data (before dropna for modeling)
        missing_val = (df.isnull().mean() * 100).sort_values(ascending=False).round(2)

        # Interactive Plotly Chart for "Excellent" visualization
        fig_missing = px.bar(missing_val[missing_val > 0],
                             x=missing_val[missing_val > 0].index,
                             y=missing_val[missing_val > 0].values,
                             title="Percentage of Missing Values per Feature (Interactive)",
                             labels={'y':'Missing %', 'x':'Feature'},
                             color=missing_val[missing_val > 0].values,
                             color_continuous_scale=px.colors.sequential.Reds)
        st.plotly_chart(fig_missing, use_container_width=True)

        if missing_val[missing_val > 0].empty:
            st.success("No missing values detected after initial data cleaning.")

        # --- City-wise Count ---
        st.subheader("City-wise Record Count (Top 15)")
        city_counts = df['City'].value_counts().head(15)
        # Interactive Plotly Chart
        fig_city = px.bar(city_counts, x=city_counts.index, y=city_counts.values,
                          title="Record Count by City",
                          labels={'y':'Number of Records', 'x':'City'},
                          color=city_counts.values,
                          color_continuous_scale=px.colors.qualitative.Pastel)
        st.plotly_chart(fig_city, use_container_width=True)


# ==============================================================================
# 2. EXPLORATORY DATA ANALYSIS (EDA) PAGE (Based on User Snippet 3, enhanced with Plotly)
# ==============================================================================
elif selection == "ðŸ“Š Exploratory Data Analysis (EDA)":
    st.header("ðŸ“ˆ Exploratory Data Analysis (Interactive)")

    if not df.empty:
        # Preprocess: drop NAs for reliable statistical analysis and plots
        df_eda = df.dropna(subset=['PM2.5','PM10','NO2','CO','SO2','O3'])

        pollutants = ['PM2.5','PM10','NO','NO2','CO','SO2','O3', 'Benzene', 'Toluene', 'Xylene', 'AQI']

        st.subheader("1. Pollutant Distribution")
        col_dist, col_filt = st.columns([3, 1])

        with col_filt:
            selected = st.selectbox("Select Pollutant", pollutants, index=pollutants.index('PM2.5'))
            log_scale = st.checkbox("Apply Log Scale", value=False)

        with col_dist:
            # Interactive Plotly Histogram (replaces Matplotlib/Seaborn)
            fig_hist = px.histogram(df_eda, x=selected,
                                    title=f"Distribution of {selected}",
                                    marginal="box",
                                    nbins=50,
                                    log_y=log_scale,
                                    color_discrete_sequence=['#1f77b4'])
            fig_hist.update_layout(xaxis_title=f"{selected} Concentration", yaxis_title="Count")
            st.plotly_chart(fig_hist, use_container_width=True)

        st.markdown("""
        **Interpretation:** The marginal box plot helps visualize outliers. Most pollutants exhibit a right-skewed distribution,
        justifying the use of median imputation during model preprocessing.
        """)

        st.subheader("2. Correlation Heatmap (Interactivity for Insights)")

        corr_cols = [p for p in pollutants if p != 'AQI']
        corr = df_eda[corr_cols].corr()

        # Interactive Plotly Heatmap (replaces Matplotlib/Seaborn)
        fig_corr = px.imshow(corr,
                             text_auto=".2f",
                             aspect="auto",
                             color_continuous_scale='Viridis',
                             title="Feature Correlation Matrix")

        # Add a tooltip for extra interactivity
        fig_corr.update_traces(hovertemplate="Feature 1: %{x}<br>Feature 2: %{y}<br>Correlation: %{z}<extra></extra>")
        st.plotly_chart(fig_corr, use_container_width=True)

        st.markdown("""
        **Insight (from user):** PM2.5 shows strong correlation with PM10 and NO2,
        indicating shared emission sources. **Advanced Insight:** Toluene, Benzene, and Xylene (VOCs) are also highly correlated,
        suggesting they likely originate from similar industrial or traffic sources.
        """)

        st.subheader("3. Time Series Analysis")
        selected_city_ts = st.selectbox("Select City for Time Series", df_eda['City'].unique(), index=0)

        df_city = df_eda[df_eda['City'] == selected_city_ts]

        fig_ts = px.line(df_city, x='Date', y='AQI',
                         title=f"AQI Trend Over Time in {selected_city_ts}",
                         color_discrete_sequence=['#d62728'])
        fig_ts.update_xaxes(rangeslider_visible=True, rangeselector=dict(
            buttons=list([
                dict(count=1, label="1m", step="month", stepmode="backward"),
                dict(count=6, label="6m", step="month", stepmode="backward"),
                dict(step="all")
            ])
        ))
        st.plotly_chart(fig_ts, use_container_width=True)


# ==============================================================================
# 3. MODELLING & PREDICTION PAGE (Based on User Snippet 4)
# ==============================================================================
elif selection == "ðŸ¤– Modelling & Prediction":
    st.header("ðŸ¤– PM2.5 Prediction (XGBoost Regressor)")

    # --- Model Loading and Warning ---
    model_path = "models/xgboost_pm25.pkl"

    st.warning(f"""
    **Action Required:** This section requires the pre-trained model file: `{model_path}`.
    Please ensure your trained **XGBoost Regressor** is saved at this exact location.
    """)

    try:
        with open(model_path, "rb") as f:
            model = pickle.load(f)

        st.success("Model loaded successfully!")
        st.subheader("Enter Pollutant Levels for PM2.5 Prediction")

        # --- Interactive Input Sliders ---
        # Note: Input features must match the features used for model training: PM10, NO2, CO, SO2, O3

        df_clean = df.dropna(subset=['PM10', 'NO2', 'CO', 'SO2', 'O3'])

        input_features = ['PM10', 'NO2', 'CO', 'SO2', 'O3']

        # Use columns for clean layout
        cols = st.columns(len(input_features))

        user_inputs = {}

        for i, feature in enumerate(input_features):
            min_val = float(df_clean[feature].min()) if not df_clean.empty else 0.0
            max_val = float(df_clean[feature].max()) if not df_clean.empty else 500.0
            mean_val = float(df_clean[feature].mean()) if not df_clean.empty else 50.0

            # Use columns to align the inputs horizontally
            with cols[i]:
                user_inputs[feature] = st.slider(f"**{feature}**",
                                                min_val,
                                                max_val * 1.5, # Allow values slightly above Max for scenario testing
                                                mean_val,
                                                step=0.1)

        # --- Prediction Button and Logic ---
        if st.button("Predict PM2.5"):
            # Create a numpy array from the user inputs in the correct order
            features_data = np.array([[
                user_inputs['PM10'],
                user_inputs['NO2'],
                user_inputs['CO'],
                user_inputs['SO2'],
                user_inputs['O3']
            ]])

            try:
                prediction = model.predict(features_data)[0]

                st.markdown(f"### Predicted PM2.5: <span style='color:#3366CC; font-size: 32px;'>{prediction:.2f} Âµg/mÂ³</span>", unsafe_allow_html=True)

                # AQI Categorization logic (adapted for PM2.5 thresholds)
                if prediction <= 30: status = "Good (Minimal Impact)"
                elif prediction <= 60: status = "Moderate (Minor breathing discomfort to sensitive people)"
                elif prediction <= 90: status = "Poor (Breathing discomfort to people with lung disease)"
                elif prediction <= 120: status = "Very Poor (Respiratory illness on prolonged exposure)"
                else: status = "Severe (Affects healthy people and seriously impacts those with existing diseases)"

                st.markdown(f"**Air Quality Status:** **{status}**")

            except Exception as e:
                st.error(f"Prediction Error: The model input or type may be incompatible with the loaded model. Ensure the model was trained with the features: {input_features}")


    except FileNotFoundError:
        st.error(f"Model file not found. Please ensure 'models/xgboost_pm25.pkl' is correctly placed.")
    except Exception as e:
        st.error(f"Failed to load or use the model: {e}")