# -*- coding: utf-8 -*-
"""app22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ez2Uqh00lf3GpqQqbIYOTU1o3IaJLS_U
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# -----------------------------------------------------------------------------
# 1. PAGE CONFIGURATION & STYLING
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="Air Quality Analysis & Prediction",
    page_icon="üåç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for a cleaner look
st.markdown("""
<style>
    .main {
        background-color: #f5f5f5;
    }
    .st-emotion-cache-16idsys p {
        font-size: 1.1rem;
    }
    h1, h2, h3 {
        color: #2c3e50;
    }
    .metric-card {
        background-color: #ffffff;
        border-left: 5px solid #3498db;
        padding: 15px;
        border-radius: 5px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# 2. DATA LOADING & PREPROCESSING FUNCTIONS
# -----------------------------------------------------------------------------
@st.cache_data
def load_and_clean_data():
    """
    Loads the dataset, handles missing values (grouped by City),
    and creates feature engineering columns (Year, Season).
    """
    # Replace this filename with your actual path if different
    file_path = 'all_cities_combined.csv'

    try:
        df = pd.read_csv(file_path)
    except FileNotFoundError:
        st.error(f"File '{file_path}' not found. Please ensure the CSV is in the app directory.")
        return None

    # Convert Date
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
    df.sort_values(by=['City', 'Date'], inplace=True)

    # Remove Duplicates
    df.drop_duplicates(inplace=True)

    # Impute Missing Values (Forward & Backward Fill by City)
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

    # We explicitly include AQI columns if they exist
    cols_to_fill = numeric_cols + ['AQI_Bucket']
    # Filter only columns that actually exist in the dataframe
    cols_to_fill = [c for c in cols_to_fill if c in df.columns]

    # Fill numeric
    df[numeric_cols] = df.groupby('City')[numeric_cols].ffill()
    df[numeric_cols] = df.groupby('City')[numeric_cols].bfill()
    # Fill categorical (AQI_Bucket)
    if 'AQI_Bucket' in df.columns:
        df['AQI_Bucket'] = df.groupby('City')['AQI_Bucket'].ffill()
        df['AQI_Bucket'] = df.groupby('City')['AQI_Bucket'].bfill()

    # Drop any remaining rows that are completely empty for a city
    df.dropna(subset=['PM2.5'], inplace=True)

    # Feature Engineering
    df['Year'] = df['Date'].dt.year
    df['Month'] = df['Date'].dt.month_name()

    def get_season(month):
        if month in [12, 1, 2]: return 'Winter'
        elif month in [3, 4, 5]: return 'Summer'
        elif month in [6, 7, 8]: return 'Monsoon'
        else: return 'Post-Monsoon'

    df['Season'] = df['Date'].dt.month.apply(get_season)

    return df

# Load Data
df = load_and_clean_data()

# -----------------------------------------------------------------------------
# 3. SIDEBAR CONTROLS
# -----------------------------------------------------------------------------
st.sidebar.header("üïπÔ∏è Dashboard Controls")

if df is not None:
    # City Filter
    city_list = sorted(df['City'].unique())
    selected_cities = st.sidebar.multiselect(
        "Select Cities to Compare",
        options=city_list,
        default=["Delhi", "Mumbai", "Bengaluru", "Chennai"] if len(city_list) > 4 else city_list[:1]
    )

    # Date Range Filter
    min_date = df['Date'].min()
    max_date = df['Date'].max()

    start_date, end_date = st.sidebar.date_input(
        "Select Date Range",
        [min_date, max_date],
        min_value=min_date,
        max_value=max_date
    )

    # Filter the Dataframe based on selection
    mask = (df['City'].isin(selected_cities)) & \
           (df['Date'] >= pd.to_datetime(start_date)) & \
           (df['Date'] <= pd.to_datetime(end_date))
    filtered_df = df[mask]

    st.sidebar.markdown("---")
    st.sidebar.info(f"Showing data for **{len(selected_cities)}** cities across **{len(filtered_df)}** records.")

# -----------------------------------------------------------------------------
# 4. MAIN DASHBOARD UI
# -----------------------------------------------------------------------------
if df is not None:
    st.title("üåç Air Quality Analysis & Prediction Dashboard")
    st.markdown("### Interactive exploration of pollution levels across Indian cities")

    # --- TABS FOR DIFFERENT VIEWS ---
    tab1, tab2, tab3 = st.tabs(["üìä Exploratory Data Analysis", "üå¶Ô∏è Seasonal & Advanced Trends", "ü§ñ ML Prediction Lab"])

    # =========================================================================
    # TAB 1: EDA
    # =========================================================================
    with tab1:
        st.subheader("General Overview")

        # Key Metrics Row
        col1, col2, col3, col4 = st.columns(4)
        avg_aqi = filtered_df['AQI'].mean()
        max_pm25 = filtered_df['PM2.5'].max()
        worst_city = filtered_df.loc[filtered_df['PM2.5'].idxmax()]['City']
        total_days = filtered_df['Date'].nunique()

        with col1:
            st.metric("Avg AQI (Selected Period)", f"{avg_aqi:.2f}", delta_color="inverse")
        with col2:
            st.metric("Max PM2.5 Recorded", f"{max_pm25:.2f} ¬µg/m¬≥")
        with col3:
            st.metric("City with Max Pollution", worst_city)
        with col4:
            st.metric("Total Days Analyzed", total_days)

        st.markdown("---")

        # 1. Interactive Time Series
        st.subheader("üìà Pollutant Trends Over Time")
        pollutant = st.selectbox("Select Pollutant to Visualize",
                                 ['PM2.5', 'PM10', 'NO2', 'CO', 'SO2', 'O3', 'AQI'])

        fig_line = px.line(filtered_df, x='Date', y=pollutant, color='City',
                           title=f'{pollutant} Levels Over Time',
                           template='plotly_white', markers=False)
        fig_line.update_layout(hovermode="x unified", xaxis_title="Date", yaxis_title=pollutant)
        st.plotly_chart(fig_line, use_container_width=True)

        col_a, col_b = st.columns(2)

        # 2. Box Plot (Distribution)
        with col_a:
            st.subheader("üì¶ Pollutant Distribution Comparison")
            fig_box = px.box(filtered_df, x='City', y=pollutant, color='City',
                             title=f'Distribution of {pollutant} by City')
            st.plotly_chart(fig_box, use_container_width=True)

        # 3. Correlation Heatmap
        with col_b:
            st.subheader("üî• Correlation Matrix")
            # Select only numeric columns for correlation
            corr_cols = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'AQI']
            corr_df = filtered_df[corr_cols].corr()

            fig_heat = px.imshow(corr_df, text_auto=True, aspect="auto",
                                 color_continuous_scale='RdBu_r',
                                 title="Correlation between Pollutants")
            st.plotly_chart(fig_heat, use_container_width=True)

    # =========================================================================
    # TAB 2: SEASONAL & ADVANCED
    # =========================================================================
    with tab2:
        st.subheader("Seasonal Analysis")

        # Group by Season
        seasonal_avg = filtered_df.groupby(['Season', 'City'])[pollutant].mean().reset_index()

        # Bar Chart
        fig_season = px.bar(seasonal_avg, x='Season', y=pollutant, color='City',
                            barmode='group',
                            title=f"Average {pollutant} Concentration by Season",
                            category_orders={"Season": ["Winter", "Summer", "Monsoon", "Post-Monsoon"]})
        st.plotly_chart(fig_season, use_container_width=True)

        st.markdown("---")

        # AQI Bucket Analysis
        st.subheader("AQI Category Distribution")
        if 'AQI_Bucket' in filtered_df.columns:
            aqi_counts = filtered_df.groupby(['City', 'AQI_Bucket']).size().reset_index(name='Counts')
            fig_sunburst = px.sunburst(aqi_counts, path=['City', 'AQI_Bucket'], values='Counts',
                                       title="AQI Category Hierarchical View")
            st.plotly_chart(fig_sunburst, use_container_width=True)
        else:
            st.warning("AQI_Bucket column not found in dataset.")

    # =========================================================================
    # TAB 3: MACHINE LEARNING
    # =========================================================================
    with tab3:
        st.header("ü§ñ Machine Learning Prediction Lab")
        st.markdown("Train a Random Forest model to predict **PM2.5** levels based on other atmospheric factors.")

        col_ml_1, col_ml_2 = st.columns([1, 2])

        with col_ml_1:
            st.markdown("### ‚öôÔ∏è Model Configuration")

            # Feature Selection
            available_features = ['PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene', 'AQI']
            # Filter features that exist in df
            valid_features = [f for f in available_features if f in df.columns]

            selected_features = st.multiselect("Select Input Features (X)", valid_features, default=valid_features[:5])
            target_var = "PM2.5"

            split_size = st.slider("Train/Test Split Ratio", 0.1, 0.5, 0.2)
            n_estimators = st.slider("Number of Trees (n_estimators)", 10, 200, 50, step=10)

            train_btn = st.button("üöÄ Train Model")

        with col_ml_2:
            if train_btn:
                if not selected_features:
                    st.error("Please select at least one feature!")
                else:
                    with st.spinner("Training Random Forest Model..."):
                        # Prepare Data
                        # Drop rows where target or features are NaN (just in case)
                        ml_df = df.dropna(subset=[target_var] + selected_features)

                        X = ml_df[selected_features]
                        y = ml_df[target_var]

                        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_size, random_state=42)

                        # Train Model
                        model = RandomForestRegressor(n_estimators=n_estimators, random_state=42)
                        model.fit(X_train, y_train)

                        # Predictions
                        y_pred = model.predict(X_test)

                        # Metrics
                        mae = mean_absolute_error(y_test, y_pred)
                        mse = mean_squared_error(y_test, y_pred)
                        r2 = r2_score(y_test, y_pred)

                        # Display Metrics
                        st.success("Model Trained Successfully!")

                        m_col1, m_col2, m_col3 = st.columns(3)
                        m_col1.metric("MAE (Mean Absolute Error)", f"{mae:.2f}")
                        m_col2.metric("MSE (Mean Squared Error)", f"{mse:.2f}")
                        m_col3.metric("R¬≤ Score (Accuracy)", f"{r2:.2f}")

                        st.markdown("---")

                        # Visualization 1: Feature Importance
                        st.subheader("Feature Importance")
                        feature_imp = pd.DataFrame({
                            'Feature': selected_features,
                            'Importance': model.feature_importances_
                        }).sort_values(by='Importance', ascending=False)

                        fig_imp = px.bar(feature_imp, x='Importance', y='Feature', orientation='h',
                                         title="Which factors affect PM2.5 the most?",
                                         color='Importance', color_continuous_scale='Viridis')
                        st.plotly_chart(fig_imp, use_container_width=True)

                        # Visualization 2: Actual vs Predicted
                        st.subheader("Actual vs Predicted PM2.5")

                        # Create a small dataframe for the plot
                        res_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

                        fig_scatter = px.scatter(res_df, x='Actual', y='Predicted',
                                                 title="Prediction Accuracy (Ideal: Diagonal Line)",
                                                 opacity=0.5, trendline="ols",
                                                 trendline_color_override="red")
                        st.plotly_chart(fig_scatter, use_container_width=True)

else:
    st.info("Loading data... please wait.")

# Footer
st.markdown("---")
st.markdown("Created with ‚ù§Ô∏è using Streamlit for Air Quality Assessment Project")